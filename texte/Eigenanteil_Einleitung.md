# Einleitung in den Eigenanteil
Im Rahmen dieser Bachelorarbeit wurde mit Hilfe von selbstentwickelter sowie bestehender Software ein System zur automatisierten Analyse von Webseiten entwickelt. Dieses System untersucht die Beziehung der Anzahl von HTML-Elementen und der Usability der Webseite sowie Performance Parametern der Webseite. Für die Erhebung der Daten wurde die Programmiersprache Python mit verschiedenen Tools/Bibliotheken verwendet.
 Die Quantifizierung der HTML-Tags wurde mit Hilfe von Selenium ermöglicht. Wie in Abschnitt {Selenium} erläutert kann Selenium einen Nutzer emulieren und automatisiert Aktionen ausführen. In diesem Fall wurde Selenium verwendet, um die Anzahl der HTML-Tags auf einer Webseite zu zählen. Zu den betrachteten HTML-Tags gehörten: "<a>-Tag", "<p>-Tag", "<div>-Tag", "<img>-Tag" und der "<button>-Tag". Die Performance Parameter wurden mit Hilfe Google PageSpeed Insights ermittelt. Dieses Werkzeug wurde schon im Abschnitt {PageSpeed} vorgestellt. Es analysiert die Webseite und gibt eine Bewertung der Performance und Usability der Webseite ab. Dieser Analyse wurden folgende Parameter entnommen: "Website ID", "Overall Category", "First Contentful Paint Time", "First Contentful Paint Score", "Largest Contentful Paint Time", "Largest Contentful PaintCP Score", "Total Blocking Time", "Cumulative Layout Shift Time", "Cumulative Layout Shift Score", "Layout Shifts", "Speed Index", "Time to Interactive", "DOM Size", "Offscreen Images", "Total Byte Weight". Diese Parameter wurden automatisiert mit Hilfe der Google PageSpeed Insights API abgerufen. Letztlich wurde die Usability der Webseite mit Hilfe des Baymard Score ermittelt. Der Baymard Score wurde im Abschnitt {Baymard} vorgestellt. Die Auswahl der analysierten Webseiten wurde auch durch das Baymard Institute festgelegt, da der Baymard Score nur für bestimmte Webseiten öffentlich verfügbar ist. 
 Die erhobenen Daten wurden dann in Graphen visualisiert und einer Korrelationsanalyse unterzogen. Für die Korrelationsanalyse wurden 2 Ansätze gewählt. Zum einen wurde die Pearson Korrelation verwendet, um die lineare Abhängigkeit der Daten zu prüfen. Um jedoch nicht nur eine lineare Korrelation abzudecken wurde zusätzlich die Spearman Korrelation beziehungsweise der Rangkorrelationskoeffizient angewendet. Für die Erstellung der Graphen wurde die Matplotlib verwendet.

 # Umsetzung 
 Vorab  wurden die Webseiten und Scores vom Baymard Institute entnommen